{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from groq) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from groq) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hi\\anaconda3\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hi\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading groq-0.12.0-py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.9 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/108.9 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 20.5/108.9 kB 217.9 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 30.7/108.9 kB 220.2 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 41.0/108.9 kB 245.8 kB/s eta 0:00:01\n",
      "   ----------------------------- --------- 81.9/108.9 kB 383.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 102.4/108.9 kB 422.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 102.4/108.9 kB 422.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 102.4/108.9 kB 422.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 102.4/108.9 kB 422.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 108.9/108.9 kB 233.7 kB/s eta 0:00:00\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: h11, httpcore, httpx, groq\n",
      "Successfully installed groq-0.12.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hi\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv(r\"C:\\Users\\HI\\Desktop\\LLMs\\data.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make client which will be our gateway for requests to api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key=os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"where USA is located\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.2-3b-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (USA) is located in North America, on the continent of the Americas. It shares borders with several countries and is surrounded by oceans:\n",
      "\n",
      "- To the north: Canada\n",
      "- To the south: Mexico\n",
      "- To the east: The Atlantic Ocean\n",
      "- To the west: The Pacific Ocean\n",
      "\n",
      "The USA is also encompassed by three major bodies of water: \n",
      "\n",
      "- The Arctic Ocean to the northwest\n",
      "- The Atlantic Ocean to the east\n",
      "- The Pacific Ocean to the west \n",
      "\n",
      "Additionally, it is bounded by several countries and U.S. territories:\n",
      "\n",
      "- Alberta, British Columbia, and Saskatchewan to the northwest (by Canada)\n",
      "- Baja California and the Gulf of California to the southwest (by Mexico)\n",
      "- The U.S. Virgin Islands, Puerto Rico, Guam, American Samoa, the Northern Mariana Islands, and the U.S. Puerto Rico Marine National Monument to the southeast and south (by various islands and waters within the Caribbean)\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of the sentence, \"salaries\" is not necessarily a requirement. The sentence is highlighting the factors that influence salaries, which are important considerations in the job market. However, if we were to rephrase the sentence to make it more concise, we could say:\n",
      "\n",
      "\"In technology and finance, for instance, compensation is often higher due to high demand for skilled professionals and the industry's revenue potential.\"\n",
      "\n",
      "In this revised sentence, \"compensation\" is a more general term that encompasses not only salaries but also other forms of remuneration, such as benefits, bonuses, or stock options.None"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    # Required parameters\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''Salaries vary widely across industries, locations, and experience levels, influenced by factors like job demand,\n",
    "              educational background, and specialized skills.\n",
    "              In technology and fina\n",
    "              nce, for instance, salaries are often higher due to high demand for skilled professionals and the industryâ€™s revenue potential.'''\n",
    "        },\n",
    "        \n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"is salaries necessary?\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama3-8b-8192\",\n",
    "\n",
    "    # Controls randomness: lowering results in less random completions.\n",
    "    # As the temperature approaches zero, the model will become deterministic\n",
    "    # and repetitive.\n",
    "    temperature=0.5,\n",
    "\n",
    "    # The maximum number of tokens to generate. Requests can use up to\n",
    "    # 2048 tokens shared between prompt and completion.\n",
    "    max_tokens=1024,\n",
    "\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop=None,\n",
    "\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Print the incremental deltas returned by the LLM.\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import pandas as pd\n",
      "import csv\n",
      "\n",
      "def find_missing_values(file_name):\n",
      "    # Read the CSV file\n",
      "    data = pd.read_csv(file_name)\n",
      "\n",
      "    # Check for missing values in each column\n",
      "    for column in data.columns:\n",
      "        missing_count = data[column].isnull().sum()\n",
      "        if missing_count > 0:\n",
      "            print(f\"Column '{column}' has {missing_count} missing values\")\n",
      "\n",
      "    # Print the total count of missing values\n",
      "    total_missing_count = data.isnull().sum().sum()\n",
      "    print(f\"Total missing values in the file: {total_missing_count}\")\n",
      "\n",
      "# Example usage\n",
      "file_name = \"example.csv\"\n",
      "find_missing_values(file_name)\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\n",
    "            # Provides initial instructions or context to set the assistant's behavior. This can guide the assistant on how it should respond throughout the conversation.\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a computer programing assitant.\"\n",
    "        },\n",
    "        {\n",
    "            # Represents messages from the user asking questions or making requests\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a Python program to find missing values in csv file format.\"\n",
    "        },\n",
    "        {\n",
    "            # used to predefine what the assistant should return in response to the user's query.\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"```python\"\n",
    "        }\n",
    "    ],\n",
    "    stop=\"```\",\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content or \"\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
